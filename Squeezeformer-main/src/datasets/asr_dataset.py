# Copyright 2020 Huy Le Nguyen (@usimarit)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import json
import abc
from typing import Union
import tqdm
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences

from ..featurizers.speech_featurizers import (
    load_and_convert_to_wav, 
    convert_waveform_to_encoded_wav,
    read_raw_audio, 
    tf_read_raw_audio, 
    TFSpeechFeaturizer
)
from ..featurizers.text_featurizers import TextFeaturizer
from ..utils import feature_util, file_util, math_util, data_util

logger = tf.get_logger()


BUFFER_SIZE = 10000
AUTOTUNE = tf.data.experimental.AUTOTUNE


class BaseDataset(metaclass=abc.ABCMeta):
    """ Based dataset for all models """

    def __init__(
        self,
        data_paths: list,
        cache: bool = False,
        shuffle: bool = False,
        buffer_size: int = BUFFER_SIZE,
        indefinite: bool = False,
        drop_remainder: bool = True,
        stage: str = "train",
        **kwargs,
    ):
        self.data_paths = data_paths or []
        if not isinstance(self.data_paths, list):
            raise ValueError('data_paths must be a list of string paths')
        self.cache = cache  # whether to cache transformed dataset to memory
        self.shuffle = shuffle  # whether to shuffle tf.data.Dataset
        if buffer_size <= 0 and shuffle:
            raise ValueError("buffer_size must be positive when shuffle is on")
        self.buffer_size = buffer_size  # shuffle buffer size
        self.stage = stage  # for defining tfrecords files
        self.drop_remainder = drop_remainder  # whether to drop remainder for multi gpu training
        self.indefinite = indefinite  # Whether to make dataset repeat indefinitely -> avoid the potential last partial batch
        self.total_steps = None  # for better training visualization

    @abc.abstractmethod
    def parse(self, *args, **kwargs):
        raise NotImplementedError()

    @abc.abstractmethod
    def create(self, batch_size):
        raise NotImplementedError()


class ASRDataset(BaseDataset):
    """ Dataset for ASR using Generator """

    def __init__(
        self,
        stage: str,
        speech_featurizer: TFSpeechFeaturizer,
        text_featurizer: TextFeaturizer,
        data_paths: list,
        cache: bool = False,
        shuffle: bool = False,
        indefinite: bool = False,
        drop_remainder: bool = True,
        buffer_size: int = BUFFER_SIZE,
        input_padding_length: int = 800, #S·ªë l∆∞·ª£ng frame fixed
        label_padding_length: int = 200,   #ƒê·ªô d√†i label.
        **kwargs,
    ):
        super().__init__(
            data_paths=data_paths, 
            cache=cache, shuffle=shuffle, stage=stage, buffer_size=buffer_size,
            drop_remainder=drop_remainder, indefinite=indefinite
        )
        self.speech_featurizer = speech_featurizer
        self.text_featurizer = text_featurizer
        self.input_padding_length = input_padding_length
        self.label_padding_length = label_padding_length


    # -------------------------------- ENTRIES -------------------------------------

    def read_entries(self):
        if hasattr(self, "entries") and len(self.entries) > 0: return
        self.entries = []
        # Duy·ªát qua t·∫•t c·∫£ c√°c t·ªáp trong self.data_paths
        for file_path in self.data_paths:
            logger.info(f"Reading {file_path} ...")
            with tf.io.gfile.GFile(file_path, "r") as f:
                # ƒê·ªçc t·∫•t c·∫£ c√°c d√≤ng trong t·ªáp v√† t√°ch th√†nh c√°c ph·∫ßn t·ª≠ trong danh s√°ch.
                temp_lines = f.read().splitlines()
                # Skip the header of tsv file
                self.entries += temp_lines[1:]
        # The files is "\t" seperated
        #T√°ch d√≤ng th√†nh ba ph·∫ßn v·ªõi t·ªëi ƒëa 2 l·∫ßn t√°ch
        self.entries = [line.split("\t", 2) for line in self.entries]
        #Chuy·ªÉn transcript th√†nh chu·ªói c√°c ch·ªâ s·ªë, ƒë·∫∑c tr∆∞ng vƒÉn b·∫£n.
        for i, line in enumerate(self.entries):
            self.entries[i][-1] = " ".join([str(x) for x in self.text_featurizer.extract(line[-1]).numpy()])
        #Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c d√≤ng th√†nh m·ªôt d·∫°ng ƒë√£ ti·ªÅn x·ª≠ l√Ω.
        self.entries = np.array(self.entries)
        if self.shuffle: np.random.shuffle(self.entries)  # Mix transcripts.tsv
        self.total_steps = len(self.entries)  #C·∫≠p nh·∫≠t b∆∞·ªõc hu·∫•n luy·ªán 
# Output [
#   ['data/audio2.wav', '2.80', '8 15 23 0 1 18 5 0 25 15 21'],
#   ['data/audio3.wav', '1.95', '14 9 3 5 0 20 15 0 13 5 5 20 0 25 15 21']
# ]

    # -------------------------------- LOAD AND PREPROCESS -------------------------------------

    def generator(self):
        for path, _, indices in self.entries:
            audio = load_and_convert_to_wav(path).numpy()
            yield bytes(path, "utf-8"), audio, bytes(indices, "utf-8")


    def tf_preprocess(self, path: tf.Tensor, audio: tf.Tensor, indices: tf.Tensor):
        with tf.device("/CPU:0"):
            signal = tf_read_raw_audio(audio, self.speech_featurizer.sample_rate)
            features = self.speech_featurizer.tf_extract(signal)
            #features.shape = [T, F, 1]
            input_length = tf.cast(tf.shape(features)[0], tf.int32)   #T

            label = tf.strings.to_number(tf.strings.split(indices), out_type=tf.int32) #indices
            label_length = tf.cast(tf.shape(label)[0], tf.int32)                       # len of indices

            prediction = self.text_featurizer.prepand_blank(label)                     
            prediction_length = tf.cast(tf.shape(prediction)[0], tf.int32)

            return path, features, input_length, label, label_length, prediction, prediction_length

    def parse(self, path: tf.Tensor, audio: tf.Tensor, indices: tf.Tensor):
        """
        Returns:
            path, features, input_lengths, labels, label_lengths, pred_inp
        """
        data = self.tf_preprocess(path, audio, indices)
        _, features, input_length, label, label_length, prediction, prediction_length = data # remove path.
        return (
            data_util.create_inputs(
                inputs=features,
                inputs_length=input_length,
                predictions=prediction,
                predictions_length=prediction_length
            ),
            data_util.create_labels(
                labels=label,
                labels_length=label_length
            )
        )
    # X·ª≠ l√Ω dataset ƒë·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho qu√° tr√¨nh train/ suy lu·∫≠n.
    # Bi·∫øn ƒë·ªïi dataset th√†nh 1 dataset c√≥ batch, ƒë√£ padding, shuffle, cache, repeat v√† prefect.
    def process(self, dataset, batch_size):
        dataset = dataset.map(self.parse, num_parallel_calls=AUTOTUNE)
        """
        Returns:
            path, features, input_lengths, labels, label_lengths, pred_inp
        """
        self.total_steps = math_util.get_num_batches(self.total_steps, batch_size, drop_remainders=self.drop_remainder) # g√°n b·∫±ng 1 lu√¥n
        if self.cache:
            dataset = dataset.cache()

        #Tr·ªôn ng·∫´u nhi√™n dataset, tr·ªôn l·∫°i d·ªØ li·ªáu sau m·ªói epoch.
        if self.shuffle:
            dataset = dataset.shuffle(self.buffer_size, reshuffle_each_iteration=True)

        #S·ªë b∆∞·ªõc l·∫∑p l·∫°i d·ª±a v√†o s·ªë batch, ko c·∫ßn cho infer
        if self.indefinite and self.total_steps:
            dataset = dataset.repeat()
        # Gom c√°c N m·∫´u l·∫°i th√†nh batch, t·ª± ƒë·ªông padding c√°c tensor ƒë·ªÉ c√≥ c√πng k√≠ch th∆∞·ªõc v·ªõi ph·∫ßn t·ª≠ d√†i nh·∫•t trong batch.
        max_input_len = 0
        count_above_400 = 0
        max_label_len = 0

        for element in dataset:
            input_tensor = element[0]['inputs']
            label_tensor = element[1]['labels']
            input_len = input_tensor.shape[0]
            label_len = label_tensor.shape[0]
            
            # C·∫≠p nh·∫≠t max_input_len
            if input_len > max_input_len:
                max_input_len = input_len
            # C·∫≠p nh·∫≠t max ƒë·ªô d√†i label
            if label_len > max_label_len:
                max_label_len = label_len
            
            # Ki·ªÉm tra input_len c√≥ l·ªõn h∆°n 1600 kh√¥ng
            if input_len > 800:
                count_above_400 += 1

        print(f"üîç Max input length (T): {max_input_len}")
        print(f"üîç Number of inputs with length > 700: {count_above_400}")
        print(f"üîç Max label length: {max_label_len}")
        dataset = dataset.padded_batch(
            batch_size=batch_size,
            #Ch·ªâ ƒë·ªãnh h√¨nh d·∫°ng t·ª´ng ph·∫ßn sau khi padding
            padded_shapes=(
                data_util.create_inputs(
                    inputs=tf.TensorShape([self.input_padding_length, 80, 1]),
                    inputs_length=tf.TensorShape([]),  #ƒê·ªô d√†i th·∫≠t c·ªßa input, a single value
                    #ƒê·∫ßu ra mong mu·ªën model h·ªçc theo.
                    predictions=tf.TensorShape([self.label_padding_length]),
                    predictions_length=tf.TensorShape([])  #ƒê·ªô d√†i th·∫≠t c·ªßa chu·ªói d·ª± ƒëo√°n.
                    #C·∫ßn ƒë·ªô d√†i th·∫≠t v√¨ khi t√≠nh CTC, ch√∫ng ko t√≠nh ph·∫ßn padding, padding ƒë·ªÉ ƒë∆∞a l√†m input model
                ),
                #ko c·∫ßn c√°i n√†y.
                data_util.create_labels(
                    labels=tf.TensorShape([self.label_padding_length]),
                    labels_length=tf.TensorShape([])
                ),
            ),
            # G√≠a tr·ªã d√πng ƒë·ªÉ padding.
            padding_values=(
                data_util.create_inputs(
                    inputs=0.0,  #Cho spectrogram ƒë·∫ßu v√†o. T·∫•t c·∫£ frame ƒë∆∞·ª£c padding = 0.
                    inputs_length=0, #ko c·∫ßn padding chi·ªÅu d√†i th·ª±c t·∫ø.
                    predictions=self.text_featurizer.blank, #padding k√Ω t·ª± tr·ªëng.
                    predictions_length=0   #Chi·ªÅu d√†i label th·ª±c t·∫ø, ko c·∫ßn.
                ),
                data_util.create_labels(
                    labels=self.text_featurizer.blank, #same
                    labels_length=0                 #Same.
                )
            ),
            # c√≥ b·ªè ph·∫ßn t·ª≠ cu·ªëi c√πng hay kh√¥ng.
            drop_remainder=self.drop_remainder
        )

        # PREFETCH to improve speed of input length
        # prefectch: t·∫£i tr∆∞·ªõc batch ti·∫øp theo khi batch hi·ªán t·∫°i ƒëang x·ª≠ l√Ω.
        dataset = dataset.prefetch(AUTOTUNE)
        return dataset

    def create(self, batch_size: int):
        self.read_entries()
        if not self.total_steps or self.total_steps == 0: return print("Couldn't create")
        dataset = tf.data.Dataset.from_generator(
            self.generator,
            output_types=(tf.string, tf.string, tf.string),
            output_shapes=(tf.TensorShape([]), tf.TensorShape([]), tf.TensorShape([]))
        )
        return self.process(dataset, batch_size)


class ASRSliceDataset(ASRDataset):
    """ Dataset for ASR using Slice """

    @staticmethod
    def load(record: tf.Tensor):
        def fn(path: bytes): return load_and_convert_to_wav(path.decode("utf-8")).numpy()
        #record[0] l√† path ƒë·∫øn file √¢m thanh
        audio = tf.numpy_function(fn, inp=[record[0]], Tout=tf.string)
        #audio: tensor: d·ªØ li·ªáu √¢m thanh ƒë√£ ƒë∆∞·ª£c m√£ h√≥a l·∫°i d·∫°ng byte string c·ªßa wav
        return record[0], audio, record[2]
    # path, audio, text

    #Chia d·ªØ li·ªáu th√†nh c√°c batch v·ªõi k√≠ch th∆∞·ªõc t∆∞∆°ng ·ª©ng.
    def create(self, batch_size: int):
        self.read_entries() # ƒë·ªôc t·ªáp TSV, t√°ch d·ªØ li·ªáu th√†nh 3 ph·∫ßn, ti·ªÅn x·ª≠ l√Ω transcript v√† l∆∞u kq v√†o self.entrices
        if not self.total_steps or self.total_steps == 0: return None
        # bi·∫øn ƒë·ªïi entrices th√†nh c√°c ph·∫ßn t·ª≠ ri√™ng bi·ªát
        dataset = tf.data.Dataset.from_tensor_slices(self.entries)

        #√°p d·ª•ng h√†m self.load cho t·ª´ng ph·∫ßn t·ª≠ trong dataset.
        dataset = dataset.map(self.load, num_parallel_calls=AUTOTUNE)
        return self.process(dataset, batch_size)
    #Outputs : features, input_lengths, labels, label_lengths, pred_inp
    def preprocess_from_mic(self, waveform: np.ndarray):
        """
        Ti·ªÅn x·ª≠ l√Ω m·ªôt ƒëo·∫°n √¢m thanh l·∫•y t·ª´ micro (Tensor ƒë√£ chu·∫©n h√≥a, float32, 16Khz)
        Tr·∫£ v·ªÅ dict ph√π h·ª£p ƒë·ªÉ ƒë∆∞a v√†o model."""
        # Chuy·ªÉn text v·ªÅ indices.
        def fn(waveform: np.ndarray): return convert_waveform_to_encoded_wav(waveform, orig_sr=16000).numpy()
        audio_tensor = tf.numpy_function(fn, inp=[waveform], Tout=tf.string)
        signal = tf_read_raw_audio(audio_tensor, self.speech_featurizer.sample_rate)
        features = self.speech_featurizer.tf_extract(signal)
        #features.shape = [T, F, 1]
        input_length = tf.cast(tf.shape(features)[0], tf.int32)   #T
        # dataset = dataset.padded_batch(
        #     batch_size=1,  # D√π b·∫°n kh√¥ng mu·ªën batch size, nh∆∞ng `batch_size` l√† tham s·ªë b·∫Øt bu·ªôc
        #     padded_shapes=(
        #         data_util.create_inputs(
        #             inputs=tf.TensorShape([self.input_padding_length, 80, 1]),  # padding cho spectrogram
        #             inputs_length=tf.TensorShape([]),  # ƒë·ªô d√†i th·ª±c t·∫ø c·ªßa input
        #         ),
        #     ),
        #     padding_values=(
        #         data_util.create_inputs(
        #             inputs=0.0,  # padding cho spectrogram, 0.0 l√† gi√° tr·ªã padding cho spectrogram
        #             inputs_length=0,  # padding cho inputs_length, c√≥ th·ªÉ l√† 0 ho·∫∑c m·ªôt gi√° tr·ªã ph√π h·ª£p
        #         ),
        #     ),
        #     drop_remainder=self.drop_remainder  # N·∫øu b·∫°n mu·ªën lo·∫°i b·ªè batch kh√¥ng ƒë·∫ßy
        # )
        # Th·ª±c hi·ªán padding th·ªß c√¥ng cho spectrogram
        padded_input = tf.pad(features, [[0, self.input_padding_length - tf.shape(features)[0]], [0, 0], [0, 0]], constant_values=0.0)

        dataset = data_util.create_inputs(
            inputs=padded_input,
            inputs_length=input_length,
        )
        # T·∫°o tuple (inputs, inputs_length)
        inputs_tensor = tf.convert_to_tensor(padded_input, dtype=tf.float32)
        inputs_length_tensor = tf.convert_to_tensor(input_length, dtype=tf.int32)

        return inputs_tensor, inputs_length_tensor

        #return dataset

    def preprocess_dataset(self, tfrecord_path, shard_size=0, max_len=None):
        self.read_entries()
        if not self.total_steps or self.total_steps == 0: return None
        logger.info(f"Preprocess dataset")
        dataset = tf.data.Dataset.from_tensor_slices(self.entries)
        dataset = dataset.map(self.load, num_parallel_calls=AUTOTUNE)
        self.create_preprocessed_tfrecord(dataset, tfrecord_path, shard_size, max_len)
