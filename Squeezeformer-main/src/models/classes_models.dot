digraph "classes_models" {
rankdir=BT
charset="utf-8"
"src.models.base_model.BaseModel" [color="black", fontcolor="black", label=<{BaseModel|metrics<br ALIGN="LEFT"/>use_loss_scale : bool<br ALIGN="LEFT"/>|add_metric(metric: tf.keras.metrics.Metric)<br ALIGN="LEFT"/>compile(loss, optimizer, run_eagerly)<br ALIGN="LEFT"/>gradient_step(inputs, y_true)<br ALIGN="LEFT"/>load_weights(filepath, by_name, skip_mismatch, options)<br ALIGN="LEFT"/><I>make</I>()<br ALIGN="LEFT"/>predict_step(batch)<br ALIGN="LEFT"/><I>recognize</I>()<br ALIGN="LEFT"/><I>recognize_beam</I>()<br ALIGN="LEFT"/>save(filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)<br ALIGN="LEFT"/>save_weights(filepath, overwrite, save_format, options)<br ALIGN="LEFT"/>test_step(batch)<br ALIGN="LEFT"/>train_step(batch)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.ConformerBlock" [color="black", fontcolor="black", label=<{ConformerBlock|layer1<br ALIGN="LEFT"/>layer2<br ALIGN="LEFT"/>layer3<br ALIGN="LEFT"/>layer4<br ALIGN="LEFT"/>ln : LayerNormalization, NoneType<br ALIGN="LEFT"/>|call(inputs, training, mask, pad_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer.ConformerCtc" [color="black", fontcolor="black", label=<{ConformerCtc|dmodel : int<br ALIGN="LEFT"/>test_function : Function<br ALIGN="LEFT"/>time_reduction_factor<br ALIGN="LEFT"/>train_function : Function<br ALIGN="LEFT"/>|make_test_function()<br ALIGN="LEFT"/>make_train_function()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer.ConformerCtcAccumulate" [color="black", fontcolor="black", label=<{ConformerCtcAccumulate|gradient_accumulation<br ALIGN="LEFT"/>n_acum_step<br ALIGN="LEFT"/>n_gradients<br ALIGN="LEFT"/>time_reduction_factor<br ALIGN="LEFT"/>|apply_accu_gradients()<br ALIGN="LEFT"/>make(input_shape, batch_size)<br ALIGN="LEFT"/>train_step(batch)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.ConformerEncoder" [color="black", fontcolor="black", label=<{ConformerEncoder|conformer_blocks : list<br ALIGN="LEFT"/>conv_subsampling<br ALIGN="LEFT"/>dmodel : int<br ALIGN="LEFT"/>do : Dropout<br ALIGN="LEFT"/>linear : Dense<br ALIGN="LEFT"/>pe<br ALIGN="LEFT"/>pe_time_reduction : list<br ALIGN="LEFT"/>pre_ln : LayerNormalization<br ALIGN="LEFT"/>recover_idx : NoneType<br ALIGN="LEFT"/>reduce_idx<br ALIGN="LEFT"/>reduce_stride : int<br ALIGN="LEFT"/>time_recover_layers : list<br ALIGN="LEFT"/>time_reduce : NoneType, str<br ALIGN="LEFT"/>time_reduction_layers : list<br ALIGN="LEFT"/>xscale : float<br ALIGN="LEFT"/>|call(inputs, length, training, mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.submodules.subsampling.Conv2dSubsampling" [color="black", fontcolor="black", label=<{Conv2dSubsampling|conv1 : Conv2D<br ALIGN="LEFT"/>conv2 : Conv2D<br ALIGN="LEFT"/>ds : bool<br ALIGN="LEFT"/>dw_conv : DepthwiseConv2D<br ALIGN="LEFT"/>kernel_size : int<br ALIGN="LEFT"/>pw_conv : Conv2D<br ALIGN="LEFT"/>strides : int<br ALIGN="LEFT"/>time_reduction_factor<br ALIGN="LEFT"/>|call(inputs, training)<br ALIGN="LEFT"/>get_config()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.ConvFFModule" [color="black", fontcolor="black", label=<{ConvFFModule|conv<br ALIGN="LEFT"/>ff<br ALIGN="LEFT"/>ln : LayerNormalization<br ALIGN="LEFT"/>ln_mid : LayerNormalization<br ALIGN="LEFT"/>|call(inputs, training)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.ConvModule" [color="black", fontcolor="black", label=<{ConvModule|act1 : Activation<br ALIGN="LEFT"/>act2 : Activation<br ALIGN="LEFT"/>adaptive_scale : bool<br ALIGN="LEFT"/>bias<br ALIGN="LEFT"/>bn : SyncBatchNormalization<br ALIGN="LEFT"/>do : Dropout<br ALIGN="LEFT"/>dw_conv : DepthwiseConv2D<br ALIGN="LEFT"/>ln : LayerNormalization<br ALIGN="LEFT"/>pw_conv_1 : Conv2D<br ALIGN="LEFT"/>pw_conv_2 : Conv2D<br ALIGN="LEFT"/>res_add : Add<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>|call(inputs, training, pad_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.ctc.CtcModel" [color="black", fontcolor="black", label=<{CtcModel|augmentation : Model<br ALIGN="LEFT"/>decoder : Dense<br ALIGN="LEFT"/>encoder : Model<br ALIGN="LEFT"/>speech_featurizer : TFSpeechFeaturizer<br ALIGN="LEFT"/>text_featurizer : TextFeaturizer<br ALIGN="LEFT"/>time_reduction_factor : int<br ALIGN="LEFT"/>|add_featurizers(speech_featurizer: TFSpeechFeaturizer, text_featurizer: TextFeaturizer)<br ALIGN="LEFT"/>call(inputs, training)<br ALIGN="LEFT"/>compile(optimizer, blank, run_eagerly)<br ALIGN="LEFT"/>make(input_shape, batch_size)<br ALIGN="LEFT"/>recognize(inputs: Dict[str, tf.Tensor])<br ALIGN="LEFT"/>recognize_beam(inputs: Dict[str, tf.Tensor], lm: bool)<br ALIGN="LEFT"/>recognize_from_logits(logits: tf.Tensor, lengths: tf.Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.FFModule" [color="black", fontcolor="black", label=<{FFModule|act : Activation<br ALIGN="LEFT"/>adaptive_scale : bool<br ALIGN="LEFT"/>bias<br ALIGN="LEFT"/>do1 : Dropout<br ALIGN="LEFT"/>do2 : Dropout<br ALIGN="LEFT"/>fc_factor : float<br ALIGN="LEFT"/>ffn1 : Dense<br ALIGN="LEFT"/>ffn2 : Dense<br ALIGN="LEFT"/>ln : LayerNormalization<br ALIGN="LEFT"/>res_add : Add<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>|call(inputs, training)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.submodules.glu.GLU" [color="black", fontcolor="black", label=<{GLU|axis : int<br ALIGN="LEFT"/>|call(inputs)<br ALIGN="LEFT"/>get_config()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.IdentityLayer" [color="black", fontcolor="black", label=<{IdentityLayer|<br ALIGN="LEFT"/>|call(inputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.MHSAFFModule" [color="black", fontcolor="black", label=<{MHSAFFModule|ff<br ALIGN="LEFT"/>ln : LayerNormalization<br ALIGN="LEFT"/>ln_mid : LayerNormalization<br ALIGN="LEFT"/>mhsa<br ALIGN="LEFT"/>|call(inputs, training)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer_encoder.MHSAModule" [color="black", fontcolor="black", label=<{MHSAModule|adaptive_scale : bool<br ALIGN="LEFT"/>bias<br ALIGN="LEFT"/>do : Dropout<br ALIGN="LEFT"/>ln : LayerNormalization<br ALIGN="LEFT"/>mha<br ALIGN="LEFT"/>mha_type : str<br ALIGN="LEFT"/>res_add : Add<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>|call(inputs, training, mask, pos)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.submodules.multihead_attention.MultiHeadAttention" [color="black", fontcolor="black", label=<{MultiHeadAttention|dropout : Dropout<br ALIGN="LEFT"/>head_size<br ALIGN="LEFT"/>key : Dense<br ALIGN="LEFT"/>num_heads<br ALIGN="LEFT"/>output_size : Optional[int]<br ALIGN="LEFT"/>projection_bias : NoneType<br ALIGN="LEFT"/>projection_kernel<br ALIGN="LEFT"/>query : Dense<br ALIGN="LEFT"/>return_attn_coef : bool<br ALIGN="LEFT"/>use_projection_bias : bool<br ALIGN="LEFT"/>value : Dense<br ALIGN="LEFT"/>|build(input_shape)<br ALIGN="LEFT"/>call(inputs, training, mask)<br ALIGN="LEFT"/>call_attention(query, key, value, logits, training, mask)<br ALIGN="LEFT"/>call_qkv(query, key, value, training)<br ALIGN="LEFT"/>compute_output_shape(input_shape)<br ALIGN="LEFT"/>get_config()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.submodules.positional_encoding.PositionalEncoding" [color="black", fontcolor="black", label=<{PositionalEncoding|max_len : int<br ALIGN="LEFT"/>pe<br ALIGN="LEFT"/>|call(inputs)<br ALIGN="LEFT"/>get_config()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.submodules.multihead_attention.RelPositionMultiHeadAttention" [color="black", fontcolor="black", label=<{RelPositionMultiHeadAttention|pos_bias_u<br ALIGN="LEFT"/>pos_bias_v<br ALIGN="LEFT"/>pos_kernel<br ALIGN="LEFT"/>|build(input_shape)<br ALIGN="LEFT"/>call(inputs, training, mask)<br ALIGN="LEFT"/>relative_shift(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.submodules.time_reduction.TimeReductionLayer" [color="black", fontcolor="black", label=<{TimeReductionLayer|dw_conv : DepthwiseConv2D<br ALIGN="LEFT"/>kernel_size : int<br ALIGN="LEFT"/>pw_conv : Conv2D<br ALIGN="LEFT"/>stride : int<br ALIGN="LEFT"/>|call(inputs, training, mask, pad_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.models.conformer.ConformerCtc" -> "src.models.ctc.CtcModel" [arrowhead="empty", arrowtail="none"];
"src.models.conformer.ConformerCtcAccumulate" -> "src.models.conformer.ConformerCtc" [arrowhead="empty", arrowtail="none"];
"src.models.ctc.CtcModel" -> "src.models.base_model.BaseModel" [arrowhead="empty", arrowtail="none"];
"src.models.submodules.multihead_attention.RelPositionMultiHeadAttention" -> "src.models.submodules.multihead_attention.MultiHeadAttention" [arrowhead="empty", arrowtail="none"];
"src.models.conformer_encoder.ConvModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer1", style="solid"];
"src.models.conformer_encoder.ConvModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer2", style="solid"];
"src.models.conformer_encoder.ConvModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer3", style="solid"];
"src.models.conformer_encoder.ConvModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer4", style="solid"];
"src.models.conformer_encoder.ConvModule" -> "src.models.conformer_encoder.ConvFFModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"src.models.conformer_encoder.FFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer1", style="solid"];
"src.models.conformer_encoder.FFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer2", style="solid"];
"src.models.conformer_encoder.FFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer3", style="solid"];
"src.models.conformer_encoder.FFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer4", style="solid"];
"src.models.conformer_encoder.FFModule" -> "src.models.conformer_encoder.ConvFFModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ff", style="solid"];
"src.models.conformer_encoder.FFModule" -> "src.models.conformer_encoder.MHSAFFModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ff", style="solid"];
"src.models.conformer_encoder.MHSAFFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer1", style="solid"];
"src.models.conformer_encoder.MHSAFFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer2", style="solid"];
"src.models.conformer_encoder.MHSAFFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer3", style="solid"];
"src.models.conformer_encoder.MHSAFFModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer4", style="solid"];
"src.models.conformer_encoder.MHSAModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer1", style="solid"];
"src.models.conformer_encoder.MHSAModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer2", style="solid"];
"src.models.conformer_encoder.MHSAModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer3", style="solid"];
"src.models.conformer_encoder.MHSAModule" -> "src.models.conformer_encoder.ConformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer4", style="solid"];
"src.models.conformer_encoder.MHSAModule" -> "src.models.conformer_encoder.MHSAFFModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mhsa", style="solid"];
"src.models.submodules.glu.GLU" -> "src.models.conformer_encoder.ConvModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="act1", style="solid"];
"src.models.submodules.multihead_attention.MultiHeadAttention" -> "src.models.conformer_encoder.MHSAModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mha", style="solid"];
"src.models.submodules.multihead_attention.RelPositionMultiHeadAttention" -> "src.models.conformer_encoder.MHSAModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mha", style="solid"];
"src.models.submodules.positional_encoding.PositionalEncoding" -> "src.models.conformer_encoder.ConformerEncoder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="pe", style="solid"];
"src.models.submodules.subsampling.Conv2dSubsampling" -> "src.models.conformer_encoder.ConformerEncoder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv_subsampling", style="solid"];
}
